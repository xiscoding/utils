## edits to llama2.c

### check directory for .bin files
#NOTE: gpt addition, checks that the folder provided has .bin files in it
def check_data_files(data_dir):
    # Check if the data directory exists
    if not os.path.exists(data_dir):
        raise ValueError(f"Data directory '{data_dir}' does not exist.")
    # Get a list of files in the data directory with the required extension
    files_with_extension = glob.glob(os.path.join(data_dir, "*.bin"))
    # Check if there are any files with the required extension
    if not files_with_extension:
        raise ValueError(f"No '.bin' files found in the data directory '{data_dir}'.")
    # You can add additional checks here if needed, depending on your specific requirements

## add progress bar to shardprocessing
#NOTE gpt addition: progress bar from tqdm
        while True:
            rng.shuffle(shard_filenames)
            for shard in tqdm(shard_filenames, desc="Processing shards", ncols=80):
                # open the dataset for reading but keep it on disk with memmap
                m = np.memmap(shard, dtype=np.uint16, mode="r")
                num_batches = len(m) // self.max_seq_len
                num_batches -= 1  # drop the last partial batch
                assert num_batches > 0, "this shard is way too small? investigate."
                ixs = list(range(num_batches))
                rng.shuffle(ixs)
                for ix in tqdm(ixs, desc="Processing batches", ncols=80):
                    start = ix * self.max_seq_len
                    end = start + self.max_seq_len + 1
                    # calling .astype will copy the data into a new numpy array, now in RAM
                    chunk = torch.from_numpy((m[start:end]).astype(np.int64))
                    x = chunk[:-1]
                    y = chunk[1:]
                    yield x, y

### minor edits
#NOTE: xdoestech edit
    ##Create folder to hold dataset and example from dataset to
    data_dir = os.path.join(DATA_CACHE_DIR, DATA_SET_NAME)
    if not os.path.exists(data_dir):
         os.makedirs(data_dir, exist_ok=True)

#NOTE: set suppress_errors to True
/home/xdoestech/anaconda3/envs/clama2/lib/python3.10/site-packages/torch/_dynamo/output_graph.py
/home/xdoestech/anaconda3/envs/clama2/lib/python3.10/site-packages/torch/_dynamo/config.py (EDIT THIS FILE)
suppress_errors = bool(os.environ.get("TORCHDYNAMO_SUPPRESS_ERRORS", True))
